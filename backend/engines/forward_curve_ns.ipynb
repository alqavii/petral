{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys  \n",
    "import datetime\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils.tte import tte\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"../data/cl/processed\") \n",
    "\n",
    "rolled_raw = pd.read_csv(DATA_DIR / \"cl_front_month_raw.csv\")\n",
    "panama_rolled = pd.read_csv(DATA_DIR / \"cl_front_month_panama_adjusted.csv\")\n",
    "proportional_rolled = pd.read_csv(DATA_DIR / \"cl_front_month_proportional_adjusted.csv\")\n",
    "\n",
    "spreads = pd.read_csv(DATA_DIR / \"cl_spreads.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"../data/cl/processed/cl_raw.csv\", index_col=0, parse_dates=True)\n",
    "raw[[\"letters\", \"number\"]] = raw[\"symbol\"].str.extract(r\"([a-zA-Z]+)([0-9]+)\")\n",
    "raw[\"number\"] = raw[\"number\"].astype(int)\n",
    "raw = raw.sort_values(by=[\"ts_event\", \"number\", \"letters\"]).reset_index()\n",
    "raw[\"month\"] = raw[\"letters\"].str[-1]\n",
    "raw = raw.drop(columns=[\"letters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[[\"ts_event\", \"symbol\", \"volume\", \"month\", \"number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[\"expiration_year\"] = np.where((raw[\"ts_event\"].dt.year//10 *10)+raw[\"number\"]<raw[\"ts_event\"].dt.year,((raw[\"ts_event\"].dt.year//10)+1)*10,(raw[\"ts_event\"].dt.year//10)*10) + raw[\"number\"] #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "month_codes = \"FGHJKMNQUVXZ\"\n",
    "\n",
    "conversions = {\n",
    "    \"F\": \"-12-25\",\n",
    "    \"G\": \"-01-25\",\n",
    "    \"H\": \"-02-25\",\n",
    "    \"J\": \"-03-25\",\n",
    "    \"K\": \"-04-25\",\n",
    "    \"M\": \"-05-25\",\n",
    "    \"N\": \"-06-25\",\n",
    "    \"Q\": \"-07-25\",\n",
    "    \"U\": \"-08-25\",\n",
    "    \"V\": \"-09-25\",\n",
    "    \"X\": \"-10-25\",\n",
    "    \"Z\": \"-11-25\"\n",
    "}\n",
    "\n",
    "#pattern = rf'^CL[{month_codes}]\\d$'\n",
    "\n",
    "raw[\"expiration_date\"] = pd.to_datetime((raw[\"expiration_year\"].astype(str) + raw[\"month\"].map(conversions))) #type: ignore\n",
    "raw[\"expiration_date\"] = raw[\"expiration_date\"].dt.tz_localize(\"UTC\") #type: ignore\n",
    "raw[\"expiration_date\"] = raw[\"expiration_date\"] - pd.offsets.BusinessDay(3)\n",
    "raw.loc[raw[\"month\"] == \"F\", \"expiration_date\"] = pd.to_datetime((raw[\"expiration_date\"].loc[raw[\"month\"] == \"F\"].dt.year.astype(int) - 1).astype(str) + \"-12-25\").dt.tz_localize(\"UTC\") - pd.offsets.BusinessDay(3)  #type: ignore\n",
    "\n",
    "raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[\"tte\"] = (raw[\"expiration_date\"] - raw[\"ts_event\"]).dt.days / 365.25 #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw = raw.drop(columns=[\"number\", \"month\", \"expiration_year\"])\n",
    "spreads[[\"ts_event\", \"symbol\", \"close\", \"volume\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_month = rf'^CL[{month_codes}]\\d$'\n",
    "second_month = rf'^CL[{month_codes}]\\d$'\n",
    "\n",
    "\n",
    "#spreads[[\"letters\"]] = spreads[\"symbol\"].str.extract() #type: ignore\n",
    "spreads[[\"month_from\", \"year_from\", \"month_to\", \"year_to\"]] = spreads[\"symbol\"].str.extract(rf\"CL([{month_codes}])([0-9])-CL([{month_codes}])([0-9])\")\n",
    "spreads = spreads[[\"ts_event\", \"symbol\", \"close\", \"volume\", \"month_from\", \"year_from\", \"month_to\", \"year_to\"]]\n",
    "spreads[\"year_from\"] = spreads[\"year_from\"].astype(int)\n",
    "spreads[\"year_to\"] = spreads[\"year_to\"].astype(int)\n",
    "spreads[\"ts_event\"] = pd.to_datetime(spreads[\"ts_event\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#spreads[\"from_date\"] = pd.to_datetime(((np.where((spreads[\"ts_event\"].dt.year//10 *10)+spreads[\"year_from\"]<spreads[\"ts_event\"].dt.year,2020,2010) + spreads[\"year_from\"]).astype(str)+ spreads[\"month_from\"].map(conversions))).dt.tz_localize('UTC') #type: ignore\n",
    "#spreads[\"to_date\"] = pd.to_datetime(((np.where((spreads[\"ts_event\"].dt.year//10 *10)+spreads[\"year_to\"]<spreads[\"ts_event\"].dt.year,2020,2010) + spreads[\"year_to\"]).astype(str)+ spreads[\"month_to\"].map(conversions))).dt.tz_localize('UTC') #type: ignore\n",
    "#\n",
    "#spreads[\"year\"] = spreads[\"ts_event\"].dt.year//10 * 10 #type: ignore\n",
    "#spreads[\"number\"] = spreads[\"year_from\"]\n",
    "#spreads[\"test_year\"] = spreads[\"year\"] + spreads[\"number\"]\n",
    "#spreads[\"test2\"] = np.where(spreads[\"test_year\"]<spreads[\"ts_event\"].dt.year, spreads[\"test_year\"]+10, spreads[\"test_year\"]) #type: ignore\n",
    "#spreads[[\"ts_event\", \"tte\", \"year\", \"year_from\", \"test_year\", \"test2\", \"from_date\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spreads[\"from_date\"] = pd.to_datetime(((np.where((spreads[\"ts_event\"].dt.year//10 *10)+spreads[\"year_from\"]<spreads[\"ts_event\"].dt.year,((spreads[\"ts_event\"].dt.year//10)+1)*10,(spreads[\"ts_event\"].dt.year//10)*10) + spreads[\"year_from\"]).astype(str)+ spreads[\"month_from\"].map(conversions))).dt.tz_localize('UTC') #type: ignore\n",
    "spreads[\"to_date\"] = pd.to_datetime(((np.where((spreads[\"ts_event\"].dt.year//10 *10)+spreads[\"year_to\"]<spreads[\"ts_event\"].dt.year,((spreads[\"ts_event\"].dt.year//10)+1)*10,(spreads[\"ts_event\"].dt.year//10)*10) + spreads[\"year_to\"]).astype(str)+ spreads[\"month_to\"].map(conversions))).dt.tz_localize('UTC') #type: ignore\n",
    "\n",
    "spreads[\"from_date\"] = spreads[\"from_date\"] - pd.offsets.BusinessDay(3)\n",
    "spreads[\"to_date\"] = spreads[\"to_date\"] - pd.offsets.BusinessDay(3)\n",
    "\n",
    "\n",
    "spreads.loc[spreads[\"month_from\"] == \"F\", \"from_date\"] = pd.to_datetime((spreads[\"from_date\"].loc[spreads[\"month_from\"] == \"F\"].dt.year.astype(int) - 1).astype(str) + \"-12-25\").dt.tz_localize(\"UTC\") - pd.offsets.BusinessDay(3)  #type: ignore\n",
    "spreads.loc[spreads[\"month_to\"] == \"F\", \"to_date\"] = pd.to_datetime((spreads[\"to_date\"].loc[spreads[\"month_to\"] == \"F\"].dt.year.astype(int) - 1).astype(str) + \"-12-25\").dt.tz_localize(\"UTC\") - pd.offsets.BusinessDay(3)  #type: ignore\n",
    "\n",
    "spreads[\"tenor\"] = (spreads[\"to_date\"] - spreads[\"from_date\"]).dt.days / 365.25 #type: ignore\n",
    "spreads[\"tte\"] = (spreads[\"to_date\"] - spreads[\"ts_event\"]).dt.days / 365.25 #type: ignore\n",
    "\n",
    "spreads.sort_values(by=[\"ts_event\", \"year_from\", \"month_from\", \"tenor\"], inplace=True)\n",
    "\n",
    "spreads.reset_index(drop=True, inplace=True)\n",
    "spreads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw[raw[\"ts_event\"] >= pd.to_datetime(\"2011-11-27\").tz_localize(\"UTC\")].reset_index(drop=True)\n",
    "raw[[\"ts_event\", \"symbol\", \"close\", \"volume\", \"month\", \"expiration_date\", \"tte\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.loc[raw[\"ts_event\"] >= pd.to_datetime(\"2011-11-27\").tz_localize(\"UTC\")]\n",
    "df[\"month_to\"] = df[\"month\"]\n",
    "df[\"year_to\"] = df[\"number\"]\n",
    "df = df.rename(columns={\"month\": \"month_from\", \"number\": \"year_from\"})\n",
    "df = df[[\"ts_event\", \"symbol\", \"close\", \"volume\", \"month_from\",  \"year_from\", \"month_to\", \"year_to\", \"tte\"]]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = spreads.loc[spreads[\"ts_event\"] >= pd.to_datetime(\"2011-11-27\").tz_localize(\"UTC\")]\n",
    "dfs = dfs[[\"ts_event\", \"symbol\", \"close\", \"volume\", \"month_from\", \"year_from\", \"month_to\", \"year_to\", \"tte\"]]\n",
    "#dfs = dfs.rename(columns={\"month_to\": \"month\", \"year_to\": \"number\"})\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat([df, dfs], ignore_index=True)\n",
    "target.sort_values(by=[\"tte\", \"volume\"], inplace=True, ascending=[True, False])\n",
    "target.reset_index(drop=True, inplace=True)\n",
    "target = target.groupby([\"ts_event\", \"tte\"]).first().reset_index()\n",
    "#target[[\"ts_event\", \"symbol\", \"close\", \"volume\", \"tte\"]]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = target[target[\"ts_event\"] == pd.to_datetime(\"2017-11-08\").tz_localize(\"UTC\")]\n",
    "\n",
    "target[\"year_from\"] =  np.where(((target[\"ts_event\"].dt.year//10 * 10)+target[\"year_from\"])<target[\"ts_event\"].dt.year, target[\"year_from\"]+10, target[\"year_from\"]) #type: ignore\n",
    "target[\"year_to\"] =  np.where(((target[\"ts_event\"].dt.year//10 * 10)+target[\"year_to\"])<target[\"ts_event\"].dt.year, target[\"year_to\"]+10, target[\"year_to\"]) #type: ignore\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_map = {'F':1, 'G':2, 'H':3, 'J':4, 'K':5, 'M':6, 'N':7, 'Q':8, 'U':9, 'V':10, 'X':11, 'Z':12}\n",
    "#target[\"month_from_num\"] = target[\"month_from\"].map(m_map) \n",
    "#target[\"month_to_num\"] = target[\"month_to\"].map(m_map).fillna(0).astype(int) + target[\"year_to\"]*12\n",
    "#\n",
    "#target[\"abs_from\"] = target[\"month_from_num\"] + target[\"year_from\"]*12\n",
    "#target[\"abs_to\"] = target[\"month_to_num\"] + target[\"year_to\"]*12\n",
    "#\n",
    "#start_month = target[\"abs_from\"].min()\n",
    "#target[\"idx_from\"] = target[\"abs_from\"] - start_month\n",
    "#target[\"idx_to\"] = target[\"abs_to\"] - start_month\n",
    "target[\"position_from\"] = target[\"month_from\"].map(m_map) + target[\"year_from\"]*12\n",
    "target[\"position_to\"] = target[\"month_to\"].map(m_map) + target[\"year_to\"]*12\n",
    "start_month = target[\"position_from\"].min()\n",
    "target[\"position_from\"] = target[\"position_from\"] - start_month\n",
    "target[\"position_to\"] = target[\"position_to\"] - start_month\n",
    "\n",
    "target[target[\"ts_event\"] == pd.to_datetime(\"2020-11-08\").tz_localize(\"UTC\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = np.arange(len(target))\n",
    "A = np.zeros((len(target), target[\"position_to\"].max()+1))\n",
    "A[row_indices, target[\"position_to\"]] = -1\n",
    "A[row_indices, target[\"position_from\"]] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, residuals, rank, s = np.linalg.lstsq(A, target[\"close\"], rcond=None)\n",
    "result = pd.DataFrame()\n",
    "result[\"date\"] = target[\"ts_event\"]\n",
    "result[\"symbol\"] = \"CL\" + target[\"month_to\"] + (target[\"year_to\"] % 10).astype(str)\n",
    "result[\"close\"] = np.round(x[target[\"position_to\"]], 3)\n",
    "result[\"volume\"] = target[\"volume\"]\n",
    "result[\"tte\"] = target[\"tte\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result[\"tte\"] <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "available = []\n",
    "for date, row in result.groupby(\"date\"):\n",
    "    available.append((date, len(row)))\n",
    "print(f\"there are on average {np.mean([a[1] for a in available]):.2f} contracts available per date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result[\"date\"] == pd.to_datetime(\"2020-11-08\").tz_localize(\"UTC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(drop=True, inplace=True)\n",
    "result.to_csv(DATA_DIR / \"cl_forward_curve_reconstructed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = result[result[\"date\"] == pd.to_datetime(\"2020-11-08\").tz_localize(\"UTC\")]\n",
    "plt.plot(slice[\"tte\"], slice[\"close\"], label='Raw Forward Curve', marker='o')\n",
    "plt.title('WTI Crude Forward Curve on 2017-11-08')\n",
    "plt.xlabel('Time to Expiration (Years)')\n",
    "plt.ylabel('Price (USD)')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6)\n",
    "fig.set_dpi(600)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import beta\n",
    "\n",
    "\n",
    "def nelson_siegel_svensson(tau, beta0, beta1, beta2, beta3, lambda1, lambda2):\n",
    "    term1 = (1-np.exp(-tau / lambda1))/(tau/lambda1)\n",
    "    term2 = term1 - np.exp(-tau / lambda1)\n",
    "    term3 = (1-np.exp(-tau / lambda2))/(tau/lambda2) - np.exp(-tau / lambda2)\n",
    "    return beta0 + beta1 * term1 + beta2 * term2 + beta3 * term3\n",
    "\n",
    "def nelson_siegel(tau, beta0, beta1, beta2, lambda_):\n",
    "    term1 = (1 - np.exp(-tau / lambda_)) / (tau / lambda_)\n",
    "    term2 = term1 - np.exp(-tau / lambda_)\n",
    "    return beta0 + beta1 * term1 + beta2 * term2\n",
    "\n",
    "def objective_s(x, tau, close):\n",
    "    beta0, beta1, beta2, beta3, lambda1, lambda2 = x\n",
    "    prices = nelson_siegel_svensson(tau, beta0, beta1, beta2, beta3, lambda1, lambda2)\n",
    "    loss = np.sum((prices - close) ** 2)\n",
    "    return loss\n",
    "\n",
    "def objective(x, tau, close):\n",
    "    beta0, beta1, beta2, lambda_ = x\n",
    "    prices = nelson_siegel(tau, beta0, beta1, beta2, lambda_)\n",
    "    loss = np.sum((prices - close) ** 2)\n",
    "    return loss\n",
    "\n",
    "def initial_guess_ns(tau, close):\n",
    "    beta0 = np.mean(close[-3:]) if len(close) >=3 else np.mean(close)\n",
    "    beta1 = close[0] - beta0\n",
    "    if len(close) >=2:\n",
    "        middle_idx = len(close)//2\n",
    "        expected_middle = beta0 + beta1 * ((1 - np.exp(-tau[middle_idx]/1.0)) / (tau[middle_idx]/1.0))\n",
    "        beta2 = close[middle_idx] - expected_middle\n",
    "    else:\n",
    "        beta2 = 0.0\n",
    "    \n",
    "    lambda_ = np.percentile(tau, 40)\n",
    "    return [beta0, beta1, beta2, lambda_]\n",
    "\n",
    "def initial_guess_nss(tau, close):\n",
    "    beta0 = np.mean(close[-3:]) if len(close) >=3 else np.mean(close)\n",
    "    beta1 = close[0] - beta0\n",
    "    if len(close) >=2:\n",
    "        middle_idx = len(close)//2\n",
    "        expected_middle = beta0 + beta1 * ((1 - np.exp(-tau[middle_idx]/1.0)) / (tau[middle_idx]/1.0))\n",
    "        beta2 = close[middle_idx] - expected_middle\n",
    "    else:\n",
    "        beta2 = 0.0\n",
    "\n",
    "    if len(close) >= 4:\n",
    "        \n",
    "        idx_3q = (3 * len(close)) // 4\n",
    "        m_3q = tau[0][idx_3q]\n",
    "        \n",
    "    \n",
    "        expected_3q = (beta0 + (beta1 + beta2) * \n",
    "                      ((1 - np.exp(-m_3q / 1.0)) / (m_3q / 1.0)))    \n",
    "        nss_factor = ((1 - np.exp(-m_3q / 1.0)) / (m_3q / 1.0) - \n",
    "                      np.exp(-m_3q / 1.0))\n",
    "        if abs(nss_factor) > 1e-6:\n",
    "            beta3 = (close[idx_3q] - expected_3q) / nss_factor\n",
    "        else:\n",
    "            beta3 = 0.0\n",
    "    else:\n",
    "        beta3 = 0.0\n",
    "\n",
    "    lambda1 = np.percentile(tau, 40)\n",
    "    lambda2 = np.percentile(tau, 70)\n",
    "    return [beta0, beta1, beta2, beta3, lambda1, lambda2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "bounds_ns = [(10, 150), (-100, 100), (-100, 100), (0.01, 50)]\n",
    "\n",
    "def solve_ns_row(date, row):\n",
    "    tau = row[\"tte\"].values\n",
    "    close = row[\"close\"].values\n",
    "    x0 = initial_guess_ns(tau, close)\n",
    "    #x0 = [row[\"close\"].iloc[-1], row[\"close\"].iloc[0]-row[\"close\"].iloc[-1], 5, 0.5]\n",
    "    \n",
    "    res = minimize(objective, x0, args=(tau, close), method='L-BFGS-B', bounds=bounds_ns)\n",
    "    beta0, beta1, beta2, lambda_ = res.x\n",
    "    return {\"date\": date, \"beta0\": beta0, \"beta1\": beta1, \"beta2\": beta2, \"lambda\": lambda_}\n",
    "\n",
    "# Fit Nelson-Siegel model\n",
    "temp_results = Parallel(n_jobs=-1)(delayed(solve_ns_row)(date, row) for date, row in result.groupby(\"date\"))\n",
    "params_ns = pd.DataFrame(temp_results)\n",
    "params_ns.to_csv(DATA_DIR / \"forward_curve_ns_params.csv\", index=False)\n",
    "\n",
    "# Merge and calculate metrics\n",
    "final_ns = pd.merge(result, params_ns, on='date', how='left')\n",
    "final_ns[\"nelson_siegel\"] = nelson_siegel(final_ns[\"tte\"], final_ns[\"beta0\"], final_ns[\"beta1\"], final_ns[\"beta2\"], final_ns[\"lambda\"])\n",
    "final_ns[\"loss\"] = (final_ns[\"close\"] - final_ns[\"nelson_siegel\"])**2\n",
    "\n",
    "mae_ns = np.abs(final_ns[\"close\"] - final_ns[\"nelson_siegel\"]).mean()\n",
    "rmse_ns = np.sqrt(final_ns[\"loss\"].mean())\n",
    "print(f\"Root Mean Squared Error of Nelson-Siegel Fit: {rmse_ns:.4f}\")\n",
    "print(f\"Mean Absolute Error of Nelson-Siegel Fit: {mae_ns:.4f}\")\n",
    "mean_ns = final_ns[\"close\"].mean()\n",
    "print(f\"This is off by {rmse_ns/mean_ns:.4%} of the average price.\")\n",
    "RSS_ns = final_ns[\"loss\"].sum()\n",
    "final_ns[\"mean\"] = final_ns[\"close\"].groupby(final_ns[\"date\"]).transform('mean')\n",
    "TSS_ns = np.sum((final_ns[\"close\"] - final_ns[\"mean\"])**2)\n",
    "R_squared_ns = 1 - RSS_ns/TSS_ns\n",
    "print(f\"R-squared of Nelson-Siegel Fit: {R_squared_ns:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = final_ns[\"close\"] - final_ns[\"nelson_siegel\"]\n",
    "plt.scatter(final_ns[\"tte\"], residuals, alpha=0.5, s=1)\n",
    "plt.axhline(0, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_nss = [(10, 150), (-100, 100), (-100, 100), (-100, 100), (0.01, 50), (0.01, 50)]\n",
    "\n",
    "def solve_nss_row(date, row):\n",
    "    tau = row[\"tte\"].values\n",
    "    close = row[\"close\"].values\n",
    "    x0 = [row[\"close\"].iloc[-1], row[\"close\"].iloc[0]-row[\"close\"].iloc[-1], 5, -2, 0.5, 2.0]\n",
    "    \n",
    "    res = minimize(objective_s, x0, args=(tau, close), method='L-BFGS-B', bounds=bounds_nss)\n",
    "    beta0, beta1, beta2, beta3, lambda1, lambda2 = res.x\n",
    "    return {\"date\": date, \"beta0\": beta0, \"beta1\": beta1, \"beta2\": beta2, \"beta3\": beta3, \"lambda1\": lambda1, \"lambda2\": lambda2}\n",
    "\n",
    "# Fit Nelson-Siegel-Svensson model\n",
    "temp_results_nss = Parallel(n_jobs=-1)(delayed(solve_nss_row)(date, row) for date, row in result.groupby(\"date\"))\n",
    "params_nss = pd.DataFrame(temp_results_nss)\n",
    "params_nss.to_csv(DATA_DIR / \"forward_curve_nss_params.csv\", index=False)\n",
    "\n",
    "# Merge and calculate metrics\n",
    "final_nss = pd.merge(result, params_nss, on='date', how='left')\n",
    "final_nss[\"nelson_siegel_svensson\"] = nelson_siegel_svensson(final_nss[\"tte\"], final_nss[\"beta0\"], final_nss[\"beta1\"], final_nss[\"beta2\"], final_nss[\"beta3\"], final_nss[\"lambda1\"], final_nss[\"lambda2\"])\n",
    "final_nss[\"loss\"] = (final_nss[\"close\"] - final_nss[\"nelson_siegel_svensson\"])**2\n",
    "\n",
    "mae_nss = np.abs(final_nss[\"close\"] - final_nss[\"nelson_siegel_svensson\"]).mean()\n",
    "rmse_nss = np.sqrt(final_nss[\"loss\"].mean())\n",
    "print(f\"Root Mean Squared Error of Nelson-Siegel-Svensson Fit: {rmse_nss:.4f}\")\n",
    "print(f\"Mean Absolute Error of Nelson-Siegel-Svensson Fit: {mae_nss:.4f}\")\n",
    "mean_nss = final_nss[\"close\"].mean()\n",
    "print(f\"This is off by {rmse_nss/mean_nss:.4%} of the average price.\")\n",
    "RSS_nss = final_nss[\"loss\"].sum()\n",
    "final_nss[\"mean\"] = final_nss[\"close\"].groupby(final_nss[\"date\"]).transform('mean')\n",
    "TSS_nss = np.sum((final_nss[\"close\"] - final_nss[\"mean\"])**2)\n",
    "R_squared_nss = 1 - RSS_nss/TSS_nss\n",
    "print(f\"R-squared of Nelson-Siegel-Svensson Fit: {R_squared_nss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = final_nss[\"close\"] - final_nss[\"nelson_siegel_svensson\"]\n",
    "plt.scatter(final_nss[\"tte\"], residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
